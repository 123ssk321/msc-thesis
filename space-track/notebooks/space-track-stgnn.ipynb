{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608f6af65bf057ce"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.nn as nng \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal, temporal_signal_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:32:57.425347500Z",
     "start_time": "2024-05-08T11:32:52.220555100Z"
    }
   },
   "id": "56d0442ea7567ad4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build satellite graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "911b5f16c5ab5ec1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load satellite graph node data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f573e6072f6f74f5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "              MEAN_MOTION  ECCENTRICITY  INCLINATION  RA_OF_ASC_NODE  \\\nNORAD_CAT_ID                                                           \n53              12.173182      0.009849      47.2749      245.136139   \n1314            12.917792      0.003186      90.2439      346.489073   \n1570            12.527797      0.010160      56.0579       38.416745   \n1573            12.410282      0.006615      56.0518      218.083507   \n1574            12.370203      0.006564      56.0539      282.997424   \n\n              ARG_OF_PERICENTER  MEAN_ANOMALY  EPHEMERIS_TYPE  \\\nNORAD_CAT_ID                                                    \n53                   290.259668     93.520449               0   \n1314                 121.537524     93.047660               0   \n1570                 177.606018    281.664377               0   \n1573                 320.617156    261.950267               0   \n1574                 126.316083    331.609578               0   \n\n             CLASSIFICATION_TYPE  REV_AT_EPOCH     BSTAR  ...  OBJECT_TYPE  \\\nNORAD_CAT_ID                                              ...                \n53                             U         82552  0.001154  ...       DEBRIS   \n1314                           U         51454  0.000067  ...      PAYLOAD   \n1570                           U         66873  0.000116  ...      PAYLOAD   \n1573                           U         64321  0.000149  ...      PAYLOAD   \n1574                           U         63479  0.000209  ...      PAYLOAD   \n\n              RCS_SIZE  CONSTELLATION_DISCOS_ID           PX           PY  \\\nNORAD_CAT_ID                                                                \n53              MEDIUM                      NaN  -981.739653 -7532.454068   \n1314             LARGE                      NaN -6109.304395  1487.265525   \n1570            MEDIUM                      NaN -3549.131956  2696.045132   \n1573            MEDIUM                      NaN  2808.836400  5941.159037   \n1574            MEDIUM                      NaN  4000.103782  1984.830449   \n\n                       PZ        VX        VY        VZ            TIMESTAMP  \nNORAD_CAT_ID                                                                  \n53            2463.445980  5.185705  0.803544  4.730939  2023-12-28 00:00:00  \n1314         -4410.214654  4.005457 -0.936573 -5.909974  2023-12-28 00:00:00  \n1570          6411.820026 -5.164112 -4.866150 -0.897586  2023-12-28 00:00:00  \n1573         -4370.626680 -5.568033 -0.634834 -4.361757  2023-12-28 00:00:00  \n1574          6449.951328 -2.117379  6.781488 -0.799534  2023-12-28 00:00:00  \n\n[5 rows x 26 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_MOTION</th>\n      <th>ECCENTRICITY</th>\n      <th>INCLINATION</th>\n      <th>RA_OF_ASC_NODE</th>\n      <th>ARG_OF_PERICENTER</th>\n      <th>MEAN_ANOMALY</th>\n      <th>EPHEMERIS_TYPE</th>\n      <th>CLASSIFICATION_TYPE</th>\n      <th>REV_AT_EPOCH</th>\n      <th>BSTAR</th>\n      <th>...</th>\n      <th>OBJECT_TYPE</th>\n      <th>RCS_SIZE</th>\n      <th>CONSTELLATION_DISCOS_ID</th>\n      <th>PX</th>\n      <th>PY</th>\n      <th>PZ</th>\n      <th>VX</th>\n      <th>VY</th>\n      <th>VZ</th>\n      <th>TIMESTAMP</th>\n    </tr>\n    <tr>\n      <th>NORAD_CAT_ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53</th>\n      <td>12.173182</td>\n      <td>0.009849</td>\n      <td>47.2749</td>\n      <td>245.136139</td>\n      <td>290.259668</td>\n      <td>93.520449</td>\n      <td>0</td>\n      <td>U</td>\n      <td>82552</td>\n      <td>0.001154</td>\n      <td>...</td>\n      <td>DEBRIS</td>\n      <td>MEDIUM</td>\n      <td>NaN</td>\n      <td>-981.739653</td>\n      <td>-7532.454068</td>\n      <td>2463.445980</td>\n      <td>5.185705</td>\n      <td>0.803544</td>\n      <td>4.730939</td>\n      <td>2023-12-28 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1314</th>\n      <td>12.917792</td>\n      <td>0.003186</td>\n      <td>90.2439</td>\n      <td>346.489073</td>\n      <td>121.537524</td>\n      <td>93.047660</td>\n      <td>0</td>\n      <td>U</td>\n      <td>51454</td>\n      <td>0.000067</td>\n      <td>...</td>\n      <td>PAYLOAD</td>\n      <td>LARGE</td>\n      <td>NaN</td>\n      <td>-6109.304395</td>\n      <td>1487.265525</td>\n      <td>-4410.214654</td>\n      <td>4.005457</td>\n      <td>-0.936573</td>\n      <td>-5.909974</td>\n      <td>2023-12-28 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1570</th>\n      <td>12.527797</td>\n      <td>0.010160</td>\n      <td>56.0579</td>\n      <td>38.416745</td>\n      <td>177.606018</td>\n      <td>281.664377</td>\n      <td>0</td>\n      <td>U</td>\n      <td>66873</td>\n      <td>0.000116</td>\n      <td>...</td>\n      <td>PAYLOAD</td>\n      <td>MEDIUM</td>\n      <td>NaN</td>\n      <td>-3549.131956</td>\n      <td>2696.045132</td>\n      <td>6411.820026</td>\n      <td>-5.164112</td>\n      <td>-4.866150</td>\n      <td>-0.897586</td>\n      <td>2023-12-28 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>12.410282</td>\n      <td>0.006615</td>\n      <td>56.0518</td>\n      <td>218.083507</td>\n      <td>320.617156</td>\n      <td>261.950267</td>\n      <td>0</td>\n      <td>U</td>\n      <td>64321</td>\n      <td>0.000149</td>\n      <td>...</td>\n      <td>PAYLOAD</td>\n      <td>MEDIUM</td>\n      <td>NaN</td>\n      <td>2808.836400</td>\n      <td>5941.159037</td>\n      <td>-4370.626680</td>\n      <td>-5.568033</td>\n      <td>-0.634834</td>\n      <td>-4.361757</td>\n      <td>2023-12-28 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1574</th>\n      <td>12.370203</td>\n      <td>0.006564</td>\n      <td>56.0539</td>\n      <td>282.997424</td>\n      <td>126.316083</td>\n      <td>331.609578</td>\n      <td>0</td>\n      <td>U</td>\n      <td>63479</td>\n      <td>0.000209</td>\n      <td>...</td>\n      <td>PAYLOAD</td>\n      <td>MEDIUM</td>\n      <td>NaN</td>\n      <td>4000.103782</td>\n      <td>1984.830449</td>\n      <td>6449.951328</td>\n      <td>-2.117379</td>\n      <td>6.781488</td>\n      <td>-0.799534</td>\n      <td>2023-12-28 00:00:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced, frac1 = False, 0.25\n",
    "reduced_sample_alt_e, frac2, min_alt, max_alt, e_thres, sampled1 = False, 1.0, 500, 600, 0.2, False \n",
    "reduced_sample_leos, frac3, leo, sampled2,  = True, 0.25, 'leo4', True  # smallest LEO\n",
    "if reduced:\n",
    "    nodes_savepath = f\"../datasets/space-track-ap2-graph-node-feats-reduced-{int(frac1 * 100)}.csv\"\n",
    "elif reduced_sample_alt_e:\n",
    "    if sampled1:\n",
    "        nodes_savepath = f\"../datasets/space-track-ap2-graph-node-feats-reduced-{int(frac2 * 100)}-h-{min_alt}-{max_alt}-e-{int(e_thres * 100)}.csv\"\n",
    "    else:\n",
    "        nodes_savepath = f\"../datasets/space-track-ap2-graph-node-feats-reduced-h-{min_alt}-{max_alt}-e-{int(e_thres * 100)}.csv\"\n",
    "elif reduced_sample_leos:\n",
    "    if sampled2:\n",
    "        nodes_savepath = f\"../datasets/space-track-ap2-graph-node-feats-{leo}-reduced-{int(frac3 * 100)}.csv\"\n",
    "    else:\n",
    "        nodes_savepath = f\"../datasets/space-track-ap2-graph-node-feats-{leo}.csv\"\n",
    "else:\n",
    "    nodes_savepath = '../datasets/space-track-ap2-graph-node-feats.csv'\n",
    "\n",
    "nodes_df = pd.read_csv(nodes_savepath, memory_map=True).set_index('NORAD_CAT_ID').drop(['OBJECT_NAME', 'OBJECT_ID', 'DECAY_DATE', 'CENTER_NAME', 'REF_FRAME', 'TIME_SYSTEM', 'MEAN_ELEMENT_THEORY'], axis=1)\n",
    "nodes_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T13:17:31.849422300Z",
     "start_time": "2024-05-06T13:17:31.660036600Z"
    }
   },
   "id": "d49742cfa6b81176"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot encode Categorical columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa3e24c3ea8b2dfd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "              MEAN_MOTION  ECCENTRICITY  INCLINATION  RA_OF_ASC_NODE  \\\nNORAD_CAT_ID                                                           \n53              12.173182      0.009849      47.2749      245.136139   \n1314            12.917792      0.003186      90.2439      346.489073   \n1570            12.527797      0.010160      56.0579       38.416745   \n1573            12.410282      0.006615      56.0518      218.083507   \n1574            12.370203      0.006564      56.0539      282.997424   \n\n              ARG_OF_PERICENTER  MEAN_ANOMALY  REV_AT_EPOCH     BSTAR  \\\nNORAD_CAT_ID                                                            \n53                   290.259668     93.520449         82552  0.001154   \n1314                 121.537524     93.047660         51454  0.000067   \n1570                 177.606018    281.664377         66873  0.000116   \n1573                 320.617156    261.950267         64321  0.000149   \n1574                 126.316083    331.609578         63479  0.000209   \n\n              MEAN_MOTION_DOT  MEAN_MOTION_DDOT  ...  OBJECT_TYPE_nan  \\\nNORAD_CAT_ID                                     ...                    \n53               2.917841e-11               0.0  ...              0.0   \n1314             2.298905e-11               0.0  ...              0.0   \n1570            -6.896714e-11               0.0  ...              0.0   \n1573            -6.366198e-11               0.0  ...              0.0   \n1574            -5.747262e-11               0.0  ...              0.0   \n\n              RCS_SIZE_LARGE  RCS_SIZE_MEDIUM  RCS_SIZE_SMALL  RCS_SIZE_nan  \\\nNORAD_CAT_ID                                                                  \n53                       0.0              1.0             0.0           0.0   \n1314                     1.0              0.0             0.0           0.0   \n1570                     0.0              1.0             0.0           0.0   \n1573                     0.0              1.0             0.0           0.0   \n1574                     0.0              1.0             0.0           0.0   \n\n              CONSTELLATION_DISCOS_ID_3.0  CONSTELLATION_DISCOS_ID_4.0  \\\nNORAD_CAT_ID                                                             \n53                                    0.0                          0.0   \n1314                                  0.0                          0.0   \n1570                                  0.0                          0.0   \n1573                                  0.0                          0.0   \n1574                                  0.0                          0.0   \n\n              CONSTELLATION_DISCOS_ID_5.0  CONSTELLATION_DISCOS_ID_7.0  \\\nNORAD_CAT_ID                                                             \n53                                    0.0                          0.0   \n1314                                  0.0                          0.0   \n1570                                  0.0                          0.0   \n1573                                  0.0                          0.0   \n1574                                  0.0                          0.0   \n\n              CONSTELLATION_DISCOS_ID_nan  \nNORAD_CAT_ID                               \n53                                    1.0  \n1314                                  1.0  \n1570                                  1.0  \n1573                                  1.0  \n1574                                  1.0  \n\n[5 rows x 38 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEAN_MOTION</th>\n      <th>ECCENTRICITY</th>\n      <th>INCLINATION</th>\n      <th>RA_OF_ASC_NODE</th>\n      <th>ARG_OF_PERICENTER</th>\n      <th>MEAN_ANOMALY</th>\n      <th>REV_AT_EPOCH</th>\n      <th>BSTAR</th>\n      <th>MEAN_MOTION_DOT</th>\n      <th>MEAN_MOTION_DDOT</th>\n      <th>...</th>\n      <th>OBJECT_TYPE_nan</th>\n      <th>RCS_SIZE_LARGE</th>\n      <th>RCS_SIZE_MEDIUM</th>\n      <th>RCS_SIZE_SMALL</th>\n      <th>RCS_SIZE_nan</th>\n      <th>CONSTELLATION_DISCOS_ID_3.0</th>\n      <th>CONSTELLATION_DISCOS_ID_4.0</th>\n      <th>CONSTELLATION_DISCOS_ID_5.0</th>\n      <th>CONSTELLATION_DISCOS_ID_7.0</th>\n      <th>CONSTELLATION_DISCOS_ID_nan</th>\n    </tr>\n    <tr>\n      <th>NORAD_CAT_ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53</th>\n      <td>12.173182</td>\n      <td>0.009849</td>\n      <td>47.2749</td>\n      <td>245.136139</td>\n      <td>290.259668</td>\n      <td>93.520449</td>\n      <td>82552</td>\n      <td>0.001154</td>\n      <td>2.917841e-11</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1314</th>\n      <td>12.917792</td>\n      <td>0.003186</td>\n      <td>90.2439</td>\n      <td>346.489073</td>\n      <td>121.537524</td>\n      <td>93.047660</td>\n      <td>51454</td>\n      <td>0.000067</td>\n      <td>2.298905e-11</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1570</th>\n      <td>12.527797</td>\n      <td>0.010160</td>\n      <td>56.0579</td>\n      <td>38.416745</td>\n      <td>177.606018</td>\n      <td>281.664377</td>\n      <td>66873</td>\n      <td>0.000116</td>\n      <td>-6.896714e-11</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1573</th>\n      <td>12.410282</td>\n      <td>0.006615</td>\n      <td>56.0518</td>\n      <td>218.083507</td>\n      <td>320.617156</td>\n      <td>261.950267</td>\n      <td>64321</td>\n      <td>0.000149</td>\n      <td>-6.366198e-11</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1574</th>\n      <td>12.370203</td>\n      <td>0.006564</td>\n      <td>56.0539</td>\n      <td>282.997424</td>\n      <td>126.316083</td>\n      <td>331.609578</td>\n      <td>63479</td>\n      <td>0.000209</td>\n      <td>-5.747262e-11</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 38 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = pd.get_dummies(nodes_df, columns=['EPHEMERIS_TYPE', 'CLASSIFICATION_TYPE', 'OBJECT_TYPE', 'RCS_SIZE','CONSTELLATION_DISCOS_ID'], drop_first=False, dummy_na=True, dtype=float)\n",
    "nodes_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T13:17:39.432757100Z",
     "start_time": "2024-05-06T13:17:39.391092700Z"
    }
   },
   "id": "7000de31566677e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load satellite graph edges data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaebb058c4138d3f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "   source  target  weight        r_dist       it_dist        ct_dist  \\\n0    1585   13378       1  1.441380e+07  3.413222e+06    1658.078733   \n1   13538   16456       1  3.261385e+05  2.032948e+06    1392.352587   \n2   13538   19785       1  1.241162e+06  7.666014e+06    1561.350018   \n3   13766   16456       1  4.163467e+04  1.124264e+07     636.122198   \n4   14139   38736       1  5.548788e+05  6.963717e+02  533571.518932   \n\n           dist            timestamp  prop  \n0  1.481242e+07  2023-12-28 00:00:00  True  \n1  2.058943e+06  2023-12-28 00:00:00  True  \n2  7.765839e+06  2023-12-28 00:00:00  True  \n3  1.124272e+07  2023-12-28 00:00:00  True  \n4  7.697983e+05  2023-12-28 00:00:00  True  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>weight</th>\n      <th>r_dist</th>\n      <th>it_dist</th>\n      <th>ct_dist</th>\n      <th>dist</th>\n      <th>timestamp</th>\n      <th>prop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1585</td>\n      <td>13378</td>\n      <td>1</td>\n      <td>1.441380e+07</td>\n      <td>3.413222e+06</td>\n      <td>1658.078733</td>\n      <td>1.481242e+07</td>\n      <td>2023-12-28 00:00:00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13538</td>\n      <td>16456</td>\n      <td>1</td>\n      <td>3.261385e+05</td>\n      <td>2.032948e+06</td>\n      <td>1392.352587</td>\n      <td>2.058943e+06</td>\n      <td>2023-12-28 00:00:00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13538</td>\n      <td>19785</td>\n      <td>1</td>\n      <td>1.241162e+06</td>\n      <td>7.666014e+06</td>\n      <td>1561.350018</td>\n      <td>7.765839e+06</td>\n      <td>2023-12-28 00:00:00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13766</td>\n      <td>16456</td>\n      <td>1</td>\n      <td>4.163467e+04</td>\n      <td>1.124264e+07</td>\n      <td>636.122198</td>\n      <td>1.124272e+07</td>\n      <td>2023-12-28 00:00:00</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14139</td>\n      <td>38736</td>\n      <td>1</td>\n      <td>5.548788e+05</td>\n      <td>6.963717e+02</td>\n      <td>533571.518932</td>\n      <td>7.697983e+05</td>\n      <td>2023-12-28 00:00:00</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df = pd.read_csv(nodes_savepath.replace('node-feats', 'edges'), memory_map=True)\n",
    "edges_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T13:19:03.197709500Z",
     "start_time": "2024-05-06T13:19:03.142500Z"
    }
   },
   "id": "5296be7e3159dba0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['2023-12-28 00:00:00', '2023-12-28 01:00:00',\n       '2023-12-28 02:00:00', '2023-12-28 03:00:00',\n       '2023-12-28 04:00:00', '2023-12-28 05:00:00',\n       '2023-12-28 06:00:00', '2023-12-28 07:00:00',\n       '2023-12-28 08:00:00', '2023-12-28 09:00:00',\n       '2023-12-28 10:00:00', '2023-12-28 11:00:00',\n       '2023-12-28 12:00:00', '2023-12-28 13:00:00',\n       '2023-12-28 14:00:00', '2023-12-28 15:00:00',\n       '2023-12-28 16:00:00', '2023-12-28 17:00:00',\n       '2023-12-28 18:00:00', '2023-12-28 19:00:00',\n       '2023-12-28 20:00:00', '2023-12-28 21:00:00',\n       '2023-12-28 22:00:00', '2023-12-28 23:00:00'], dtype=object)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps = edges_df['timestamp'].unique()\n",
    "timestamps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:48:54.092637Z",
     "start_time": "2024-04-23T09:48:53.993901Z"
    }
   },
   "id": "d6668aaeecd47620"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Satellite Conjunction Prediction through Link Prediction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "494a73740171d259"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separate satellite graph edges into train set and test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a66e74cde41de9"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total edges: 4746\n",
      "Number of total edges in training set: 3725\n",
      "Number of total edges in test set: 1021\n"
     ]
    }
   ],
   "source": [
    "def temporal_signal_split(timestamps, train_ratio=0.8):\n",
    "    train_snapshots = int(train_ratio * timestamps.shape[0])\n",
    "    # necessary to reduce len(train_timestamps) timestamps to 1 such that there is only one feature matrix\n",
    "    train_snapshots = train_snapshots-1 if train_snapshots % 2 == 0 else train_snapshots\n",
    "    \n",
    "    train_timestamps = timestamps[0:train_snapshots]\n",
    "    test_timestamps = timestamps[train_snapshots:]\n",
    "    \n",
    "    return train_timestamps, test_timestamps\n",
    "\n",
    "train_timestamps, test_timestamps = temporal_signal_split(timestamps)\n",
    "\n",
    "train_edges_df = edges_df[edges_df['timestamp'].isin(train_timestamps)]\n",
    "test_edges_df = edges_df[edges_df['timestamp'].isin(test_timestamps)]\n",
    "\n",
    "print(\n",
    "    f\"Number of total edges: {edges_df.shape[0]}\\n\"\n",
    "    f\"Number of total edges in training set: {train_edges_df.shape[0]}\\n\"\n",
    "    f\"Number of total edges in test set: {test_edges_df.shape[0]}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T15:00:34.045000900Z",
     "start_time": "2024-04-17T15:00:33.939442800Z"
    }
   },
   "id": "1444041971e5da70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Separate each set edges into positive edges and negative edges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19314a467669e24e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "nodes = list(nodes_df.index.unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:49:19.248178Z",
     "start_time": "2024-04-23T09:49:19.174143100Z"
    }
   },
   "id": "4cc098cc13bbc56"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total positive edges in dataset: 4746\n",
      "Number of total negative edges in dataset: 4746\n"
     ]
    }
   ],
   "source": [
    "def sample_negative_edges_df_for_dt(nodes, positive_edges_df_in_dt, date_time):\n",
    "    positive_set = set(positive_edges_df_in_dt[[\"source\", \"target\"]].itertuples(index=False, name=None))\n",
    "\n",
    "    def valid_neg_edge(src, tgt):\n",
    "        return (\n",
    "            # no self-loops\n",
    "            src != tgt\n",
    "            and\n",
    "            # neither direction of the edge should be a positive one\n",
    "            (src, tgt) not in positive_set\n",
    "            and (tgt, src) not in positive_set\n",
    "        )\n",
    "    # TODO: Define edge weight and assing random weight here\n",
    "    possible_neg_edges = [\n",
    "        [src, tgt, 1, date_time] for src in nodes for tgt in nodes if valid_neg_edge(src, tgt)\n",
    "    ]\n",
    "    neg_edges = np.array(random.sample(possible_neg_edges, k=len(positive_set)))\n",
    "    return {'source':neg_edges[:, 0].tolist(), 'target':neg_edges[:, 1].tolist(), 'weight':neg_edges[:, 2].tolist(), 'timestamp':neg_edges[:, 3].tolist()}\n",
    "\n",
    "def sample_negative_edges_df(nodes, positive_edges_df, timestamps):\n",
    "    edges = {'source':[], 'target':[], 'weight':[], 'timestamp':[]}\n",
    "    for i in range(len(timestamps)):\n",
    "        date_time = timestamps[i]\n",
    "        edges_data = sample_negative_edges_df_for_dt(nodes, positive_edges_df[positive_edges_df['timestamp'] == date_time], date_time)\n",
    "        edges['source'] = edges['source'] + edges_data['source']\n",
    "        edges['target'] = edges['target'] + edges_data['target']\n",
    "        edges['weight'] = edges['weight'] + edges_data['weight']\n",
    "        edges['timestamp'] = edges['timestamp'] + edges_data['timestamp']\n",
    "    edges_df = pd.DataFrame(edges)\n",
    "    edges_df['source'] = edges_df['source'].astype(np.int64)\n",
    "    edges_df['target'] = edges_df['target'].astype(np.int64)\n",
    "    edges_df['weight'] = edges_df['weight'].astype(np.int64)\n",
    "    edges_df['timestamp'] = pd.to_datetime(edges_df['timestamp'])\n",
    "    return edges_df\n",
    "\n",
    "# train_pos_edges_df = train_edges_df[['source', 'target', 'weight', 'timestamp']]\n",
    "# train_neg_edges_df = sample_negative_edges_df(nodes, train_pos_edges_df, train_timestamps)\n",
    "# \n",
    "# test_pos_edges_df = test_edges_df[['source', 'target', 'weight', 'timestamp']]\n",
    "# test_neg_edges_df = sample_negative_edges_df(nodes, test_pos_edges_df, test_timestamps)\n",
    "# \n",
    "# print(\n",
    "#     f\"Number of total positive edges in training set: {train_pos_edges_df.shape[0]}\\n\"\n",
    "#     f\"Number of total negative edges in training set: {train_neg_edges_df.shape[0]}\\n\"\n",
    "#     f\"Number of total positive edges in test set: {test_pos_edges_df.shape[0]}\\n\"\n",
    "#     f\"Number of total negative edges in test set: {test_neg_edges_df.shape[0]}\\n\"\n",
    "# )\n",
    "pos_edges_df = edges_df[['source', 'target', 'weight', 'timestamp']]\n",
    "neg_edges_df = sample_negative_edges_df(nodes, pos_edges_df, timestamps)\n",
    "\n",
    "print(\n",
    "    f\"Number of total positive edges in dataset: {pos_edges_df.shape[0]}\\n\"\n",
    "    f\"Number of total negative edges in dataset: {neg_edges_df.shape[0]}\\n\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:49:38.557706400Z",
     "start_time": "2024-04-23T09:49:20.013438100Z"
    }
   },
   "id": "af0d8e5ee49d304e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build positive and negative dynamic graph static signal data iterator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d36c93a40a3e0ea9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def edges_df_to_torch_data(num_nodes, node_index, nodes_df, edges_df):\n",
    "    x = torch.tensor(nodes_df.values[:, :].astype(float))\n",
    "    \n",
    "    # Convert DataFrame to COO format\n",
    "    row = edges_df['source'].map(node_index.get)\n",
    "    col = edges_df['target'].map(node_index.get)\n",
    "    data = [1] * len(edges_df)\n",
    "    coo = coo_matrix((data, (row, col)), shape=(num_nodes, num_nodes))\n",
    "    edge_index = torch.tensor(np.array([coo.row, coo.col]), dtype=torch.long)\n",
    "    \n",
    "    edge_attr = torch.tensor(edges_df['weight'].values.astype(float))\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def to_torch_data(timestamps, num_nodes, node_index, nodes_df, edges_df):\n",
    "    torch_datas = []\n",
    "    for ts in timestamps:\n",
    "        nodes_df_ts = nodes_df[nodes_df['TIMESTAMP'] == ts]\n",
    "        edges_df_ts = edges_df[edges_df['timestamp'] == ts]\n",
    "\n",
    "        torch_data = edges_df_to_torch_data(num_nodes, node_index, nodes_df_ts.drop('TIMESTAMP', axis=1), edges_df_ts)\n",
    "        torch_datas.append(torch_data)\n",
    "    return torch_datas\n",
    "\n",
    "num_nodes = len(nodes)\n",
    "node_index = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "train_data = to_torch_data(train_timestamps, num_nodes, node_index, nodes_df, train_pos_edges_df)\n",
    "train_pos_edges_data = train_data\n",
    "train_neg_edges_data = to_torch_data(train_timestamps, num_nodes, node_index, nodes_df, train_neg_edges_df)\n",
    "\n",
    "test_pos_edges_data = to_torch_data(test_timestamps, num_nodes, node_index, nodes_df, test_pos_edges_df)\n",
    "test_neg_edges_data = to_torch_data(test_timestamps, num_nodes, node_index, nodes_df, test_neg_edges_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T18:45:22.164050400Z",
     "start_time": "2024-04-22T18:45:21.870599400Z"
    }
   },
   "id": "e06ba4ed87e203c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def feat_idx_w(num_nodes, node_index, nodes_df, edges_df):\n",
    "    x = nodes_df.values[:, :].astype(float)\n",
    "    \n",
    "    # Convert DataFrame to COO format\n",
    "    row = edges_df['source'].map(node_index.get)\n",
    "    col = edges_df['target'].map(node_index.get)\n",
    "    data = [1] * len(edges_df)\n",
    "    coo = coo_matrix((data, (row, col)), shape=(num_nodes, num_nodes))\n",
    "    edge_index = np.array([coo.row, coo.col], dtype=np.int64)\n",
    "    \n",
    "    edge_attr = edges_df['weight'].values.astype(float)\n",
    "    \n",
    "    return x, edge_index, edge_attr\n",
    "\n",
    "def to_feats_idxs_ws(timestamps, num_nodes, node_index, nodes_df, edges_df):\n",
    "    features = []\n",
    "    edge_indices = []\n",
    "    edge_weights = []\n",
    "    for ts in timestamps:\n",
    "        nodes_df_ts = nodes_df[nodes_df['TIMESTAMP'] == ts]\n",
    "        edges_df_ts = edges_df[edges_df['timestamp'] == ts]\n",
    "\n",
    "        x, edge_index, edge_attr = feat_idx_w(num_nodes, node_index, nodes_df_ts.drop('TIMESTAMP', axis=1), edges_df_ts)\n",
    "        features.append(x)\n",
    "        edge_indices.append(edge_index)\n",
    "        edge_weights.append(edge_attr)\n",
    "    return features, edge_indices, edge_weights\n",
    "\n",
    "num_nodes = len(nodes)\n",
    "node_index = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "pos_features, pos_edge_indices, pos_edge_weights = to_feats_idxs_ws(timestamps, num_nodes, node_index, nodes_df, pos_edges_df)\n",
    "pos_dataset = DynamicGraphTemporalSignal(pos_edge_indices, pos_edge_weights, pos_features, [None]*len(pos_features))\n",
    "\n",
    "neg_features, neg_edge_indices, neg_edge_weights = to_feats_idxs_ws(timestamps, num_nodes, node_index, nodes_df, neg_edges_df)\n",
    "neg_dataset = DynamicGraphTemporalSignal(neg_edge_indices, neg_edge_weights, neg_features, [None]*len(neg_features))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:51:40.789910600Z",
     "start_time": "2024-04-23T09:51:40.441690100Z"
    }
   },
   "id": "d3ec45c523b5c63a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of snapshots in train set of positive edges : 19\n",
      "Number of snapshots in train set of negative edges : 19\n",
      "Number of snapshots in test set of positive edges : 5\n",
      "Number of snapshots in test set of negative edges : 5\n"
     ]
    }
   ],
   "source": [
    "train_pos_dataset, test_pos_dataset = temporal_signal_split(pos_dataset, train_ratio=0.8)\n",
    "train_neg_dataset, test_neg_dataset = temporal_signal_split(neg_dataset, train_ratio=0.8)\n",
    "\n",
    "print(\n",
    "    f\"Number of snapshots in train set of positive edges : {train_pos_dataset.snapshot_count}\\n\"\n",
    "    f\"Number of snapshots in train set of negative edges : {train_neg_dataset.snapshot_count}\\n\"\n",
    "    f\"Number of snapshots in test set of positive edges : {test_pos_dataset.snapshot_count}\\n\"\n",
    "    f\"Number of snapshots in test set of negative edges : {test_neg_dataset.snapshot_count}\\n\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:51:44.365235700Z",
     "start_time": "2024-04-23T09:51:44.174666800Z"
    }
   },
   "id": "a15801f69582663f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Spatial-Temporal Graph Neural Network (STGNN)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47438efc007682c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN-based approach"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd28de1d6df431ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f3e6f9b462fe973f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CNN-based approach"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43e5e3b9f2c94db"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class TemporalConv(nn.Module):\n",
    "    r\"\"\" Implementation from PyTorch Geometric Temporal.\n",
    "    Temporal convolution block applied to nodes in the STGCN Layer\n",
    "    For details see: `\"Spatio-Temporal Graph Convolutional Networks:\n",
    "    A Deep Learning Framework for Traffic Forecasting.\"\n",
    "    <https://arxiv.org/abs/1709.04875>`_ Based off the temporal convolution\n",
    "     introduced in \"Convolutional Sequence to Sequence Learning\"  <https://arxiv.org/abs/1709.04875>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        kernel_size (int): Convolutional kernel size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int = 3):\n",
    "        super(TemporalConv, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv_2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv_3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \"\"\"Forward pass through temporal convolution block.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** (torch.FloatTensor) -  Input data of shape\n",
    "                (batch_size, input_time_steps, num_nodes, in_channels).\n",
    "\n",
    "        Return types:\n",
    "            * **H** (torch.FloatTensor) - Output data of shape\n",
    "                (batch_size, in_channels, num_nodes, input_time_steps).\n",
    "        \"\"\"\n",
    "        # X = X.permute(0, 3, 2, 1)\n",
    "        # P = self.conv_1(X)\n",
    "        # Q = torch.sigmoid(self.conv_2(X))\n",
    "        # PQ = P * Q\n",
    "        # H = F.relu(PQ + self.conv_3(X))\n",
    "        # H = H.permute(0, 3, 2, 1)\n",
    "        # return H\n",
    "        X = X.permute(0, 3, 2, 1)\n",
    "        P = self.conv_1(X)\n",
    "        Q = torch.sigmoid(self.conv_2(X))\n",
    "        PQ = P * Q\n",
    "        H = F.relu(PQ + self.conv_3(X))\n",
    "        H = H.permute(0, 3, 2, 1)\n",
    "        return H"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:51:51.029319200Z",
     "start_time": "2024-04-23T09:51:50.938380400Z"
    }
   },
   "id": "bffeb0437de5ffa2"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class STConv(nn.Module):\n",
    "    r\"\"\"Spatio-temporal convolution block using ChebConv Graph Convolutions.\n",
    "    For details see: `\"Spatio-Temporal Graph Convolutional Networks:\n",
    "    A Deep Learning Framework for Traffic Forecasting\"\n",
    "    <https://arxiv.org/abs/1709.04875>`_\n",
    "\n",
    "    NB. The ST-Conv block contains two temporal convolutions (TemporalConv)\n",
    "    with kernel size k. Hence for an input sequence of length m,\n",
    "    the output sequence will be length m-2(k-1).\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        hidden_channels (int): Number of hidden units output by graph convolution block\n",
    "        out_channels (int): Number of output features.\n",
    "        kernel_size (int): Size of the kernel considered.\n",
    "        K (int): Chebyshev filter size :math:`K`.\n",
    "        normalization (str, optional): The normalization scheme for the graph\n",
    "            Laplacian (default: :obj:`\"sym\"`):\n",
    "\n",
    "            1. :obj:`None`: No normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
    "\n",
    "            2. :obj:`\"sym\"`: Symmetric normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
    "            \\mathbf{D}^{-1/2}`\n",
    "\n",
    "            3. :obj:`\"rw\"`: Random-walk normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
    "\n",
    "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
    "            this operator in case the normalization is non-symmetric.\n",
    "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
    "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
    "            scalar/zero-dimensional tensor when operating on single graphs.\n",
    "            You can pre-compute :obj:`lambda_max` via the\n",
    "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph_conv: nn.Module,\n",
    "        num_nodes: int,\n",
    "        in_channels: int,\n",
    "        hidden_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        K: int,\n",
    "        normalization: str = \"sym\",\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(STConv, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "\n",
    "        self._temporal_conv1 = TemporalConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            kernel_size=kernel_size,\n",
    "        )\n",
    "\n",
    "        #self._graph_conv = graph_conv\n",
    "        \n",
    "        self._graph_conv = nng.ChebConv(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            K=K,\n",
    "            normalization=normalization,\n",
    "            bias=bias, \n",
    "        )\n",
    "\n",
    "        self._temporal_conv2 = TemporalConv(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "        )\n",
    "\n",
    "        self._batch_norm = nn.BatchNorm2d(num_nodes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "\n",
    "        r\"\"\"Forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** (PyTorch FloatTensor) - Sequence of node features of shape (Batch size X Input time steps X Num nodes X In channels).\n",
    "            * **edge_index** (PyTorch LongTensor) - Graph edge indices.\n",
    "            * **edge_weight** (PyTorch LongTensor, optional)- Edge weight vector.\n",
    "\n",
    "        Return types:\n",
    "            * **T** (PyTorch FloatTensor) - Sequence of node features.\n",
    "        \"\"\"\n",
    "        T_0 = self._temporal_conv1(X)\n",
    "        T = torch.zeros_like(T_0).to(T_0.device)\n",
    "        for b in range(T_0.size(0)):\n",
    "            for t in range(T_0.size(1)):\n",
    "                T[b][t] = self._graph_conv(T_0[b][t], edge_index, edge_weight) #original used in fst template loop\n",
    "                #T[b][t] = self._graph_conv(T_0[b][t], edge_index[t], edge_weight[t]) #used in snd template loop\n",
    "\n",
    "        T = F.relu(T)\n",
    "        T = self._temporal_conv2(T)\n",
    "        T = T.permute(0, 2, 1, 3)\n",
    "        T = self._batch_norm(T)\n",
    "        T = T.permute(0, 2, 1, 3)\n",
    "        return T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:59:13.076188900Z",
     "start_time": "2024-04-23T09:59:12.985717700Z"
    }
   },
   "id": "778ca75d10e55743"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Our final classifier applies the dot-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x:torch.Tensor, edge_index: torch.LongTensor) -> torch.Tensor:\n",
    "        # Get node embeddings\n",
    "        u_feat = x[edge_index[0]]\n",
    "        v_feat = x[edge_index[1]]\n",
    "\n",
    "        # Apply dot-product to get a prediction per supervision edge:\n",
    "        return (u_feat * v_feat).sum(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:59:14.064549500Z",
     "start_time": "2024-04-23T09:59:14.023770Z"
    }
   },
   "id": "89fbb29288cf9a01"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class STGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STGNN, self).__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:59:15.196816700Z",
     "start_time": "2024-04-23T09:59:15.163306300Z"
    }
   },
   "id": "152ee7b723d54708"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the STGNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bcbc84f488428b"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:59:16.301164200Z",
     "start_time": "2024-04-23T09:59:16.268498200Z"
    }
   },
   "id": "61e9fface82cfcd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Template for training loop when iterating through snapshots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d475a6cf5520f56a"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[801, 37], edge_index=[2, 165], edge_attr=[165])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_data = next(iter(train_pos_dataset))\n",
    "tmp_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T09:59:19.418019500Z",
     "start_time": "2024-04-23T09:59:19.393145200Z"
    }
   },
   "id": "32f0adc1367b7cdd"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[801, 37], edge_index=[2, 165], edge_attr=[165])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_neg_data = next(iter(train_neg_dataset))\n",
    "tmp_neg_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T10:00:48.897644200Z",
     "start_time": "2024-04-23T10:00:48.792512700Z"
    }
   },
   "id": "aa702c056c0eaf8e"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos score: tensor([ 2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  0.0000, -2.0000,  2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,\n",
      "         2.0000,  2.0000,  0.0000,  2.0000,  2.0000,  2.0000,  0.0000,  2.0000,\n",
      "        -2.0000, -2.0000,  2.0000,  2.0000, -2.0000,  2.0000, -2.0000, -2.0000,\n",
      "        -2.0000,  2.0000,  2.0000, -2.0000,  2.0000,  0.0000, -2.0000, -2.0000,\n",
      "         0.0000,  2.0000,  0.0000,  2.0000, -2.0000,  2.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  2.0000,  0.0000, -2.0000, -2.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.0000,  2.0000,  0.0000,\n",
      "         2.0000, -2.0000,  0.0000,  2.0000,  2.0000,  0.0000,  0.0000,  2.0000,\n",
      "         2.0000,  2.0000,  0.0000,  2.0000,  2.0000,  2.0000,  2.0000,  0.0000,\n",
      "         2.0000, -2.0000, -2.0000,  2.0000,  2.0000,  0.0000,  2.0000, -2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  0.0000,  0.0000,  2.0000,  2.0000,  2.0000,\n",
      "         2.0000, -2.0000,  2.0000,  0.0000,  2.0000, -2.0000,  2.0000,  0.0000,\n",
      "         0.0000,  0.0000, -2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  0.0000,\n",
      "         2.0000,  2.0000,  0.0000,  0.0000, -2.0000,  0.0000,  2.0000,  0.0000,\n",
      "         0.0000,  0.0000,  2.0000, -2.0000,  0.0000,  2.0000,  2.0000,  2.0000,\n",
      "         2.0000,  2.0000, -2.0000,  2.0000,  2.0000,  0.0000,  2.0000, -2.0000,\n",
      "         2.0000,  0.0000,  0.0000,  2.0000,  2.0000,  2.0000,  2.0000, -2.0000,\n",
      "         0.0000,  2.0000,  2.0000,  0.0000,  2.0000,  0.0000,  2.0000,  2.0000,\n",
      "         2.0000, -2.0000,  2.0000,  2.0000,  0.0000,  0.0000,  0.0000, -2.0000,\n",
      "         2.0000,  2.0000, -2.0000,  2.0000,  0.0000], grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([ 2.0000,  2.0000,  2.0000,  2.0000,  0.0000,  2.0000,  2.0000,  2.0000,\n",
      "         0.0000,  0.0000,  2.0000,  2.0000,  0.0000,  0.0000,  2.0000,  2.0000,\n",
      "         0.0000,  2.0000,  2.0000, -2.0000,  2.0000,  2.0000,  2.0000,  2.0000,\n",
      "        -1.9999,  0.0000,  0.0000,  2.0000,  2.0000, -2.0000, -2.0000,  2.0000,\n",
      "         2.0000, -2.0000,  2.0000,  0.0000,  0.0000,  2.0000,  2.0000,  0.0000,\n",
      "         0.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,\n",
      "         0.0000,  2.0000,  2.0000,  2.0000,  0.0000,  2.0000,  2.0000, -2.0000,\n",
      "        -2.0000,  2.0000,  2.0000,  0.0000,  2.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -2.0000, -2.0000, -2.0000,  2.0000, -2.0000, -2.0000, -2.0000,  2.0000,\n",
      "         0.0000,  2.0000, -2.0000,  0.0000,  2.0000, -2.0000,  0.0000,  2.0000,\n",
      "         2.0000,  2.0000,  0.0000,  2.0000,  0.0000,  2.0000,  0.0000,  2.0000,\n",
      "         2.0000, -2.0000, -2.0000,  2.0000,  0.0000,  2.0000, -2.0000, -2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  2.0000,  2.0000, -2.0000,  0.0000,  0.0000,\n",
      "         2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  2.0000,  0.0000,  2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  0.0000,  0.0000, -2.0000,  2.0000,  2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  0.0000,  2.0000, -2.0000,  2.0000,  0.0000,\n",
      "         0.0000,  0.0000, -2.0000,  2.0000,  2.0000,  2.0000,  0.0000,  2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  2.0000, -2.0000,  2.0000,  0.0000, -2.0000,\n",
      "         2.0000,  2.0000,  2.0000,  0.0000, -2.0000,  2.0000,  2.0000,  2.0000,\n",
      "         2.0000, -2.0000,  2.0000,  2.0000,  2.0000,  2.0000, -2.0000, -2.0000,\n",
      "         0.0000,  0.0000,  2.0000, -2.0000,  0.0000], grad_fn=<SumBackward1>)\n",
      "Loss: 1.0250900983810425\n",
      "Pos probabilities: tensor([0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.5000, 0.1192, 0.8808, 0.8808,\n",
      "        0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808, 0.8808,\n",
      "        0.5000, 0.8808, 0.8808, 0.8808, 0.5000, 0.8808, 0.1192, 0.1192, 0.8808,\n",
      "        0.8808, 0.1192, 0.8808, 0.1192, 0.1192, 0.1192, 0.8808, 0.8808, 0.1192,\n",
      "        0.8808, 0.5000, 0.1192, 0.1192, 0.5000, 0.8808, 0.5000, 0.8808, 0.1192,\n",
      "        0.8808, 0.5000, 0.5000, 0.5000, 0.5000, 0.8808, 0.5000, 0.1192, 0.1192,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.8808, 0.8808,\n",
      "        0.5000, 0.8808, 0.1192, 0.5000, 0.8808, 0.8808, 0.5000, 0.5000, 0.8808,\n",
      "        0.8808, 0.8808, 0.5000, 0.8808, 0.8808, 0.8808, 0.8808, 0.5000, 0.8808,\n",
      "        0.1192, 0.1192, 0.8808, 0.8808, 0.5000, 0.8808, 0.1192, 0.8808, 0.8808,\n",
      "        0.8808, 0.5000, 0.5000, 0.8808, 0.8808, 0.8808, 0.8808, 0.1192, 0.8808,\n",
      "        0.5000, 0.8808, 0.1192, 0.8808, 0.5000, 0.5000, 0.5000, 0.1192, 0.8808,\n",
      "        0.8808, 0.8808, 0.8808, 0.5000, 0.8808, 0.8808, 0.5000, 0.5000, 0.1192,\n",
      "        0.5000, 0.8808, 0.5000, 0.5000, 0.5000, 0.8808, 0.1192, 0.5000, 0.8808,\n",
      "        0.8808, 0.8808, 0.8808, 0.8808, 0.1192, 0.8808, 0.8808, 0.5000, 0.8808,\n",
      "        0.1192, 0.8808, 0.5000, 0.5000, 0.8808, 0.8808, 0.8808, 0.8808, 0.1192,\n",
      "        0.5000, 0.8808, 0.8808, 0.5000, 0.8808, 0.5000, 0.8808, 0.8808, 0.8808,\n",
      "        0.1192, 0.8808, 0.8808, 0.5000, 0.5000, 0.5000, 0.1192, 0.8808, 0.8808,\n",
      "        0.1192, 0.8808, 0.5000], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tmp_model = STConv(None, num_nodes, nodes_df.shape[1]-1, 12, 2, 1, 2)\n",
    "tmp_cls = Classifier()\n",
    "torch.no_grad()\n",
    "\n",
    "tmp_h = tmp_model(tmp_data.x.unsqueeze(0).unsqueeze(0), tmp_data.edge_index, tmp_data.edge_attr)\n",
    "\n",
    "pos_score = tmp_cls(tmp_h.squeeze(), tmp_data.edge_index)\n",
    "neg_score = tmp_cls(tmp_h.squeeze(), tmp_neg_data.edge_index)\n",
    "\n",
    "print(f'Pos score: {pos_score}')\n",
    "print(f'Neg score: {neg_score}')\n",
    "print(f'Loss: {compute_loss(pos_score, neg_score)}')\n",
    "print(f'Pos probabilities: {torch.sigmoid(pos_score)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T10:01:49.728972700Z",
     "start_time": "2024-04-23T10:01:49.680883200Z"
    }
   },
   "id": "b4864bf06e1398a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Template for training loop when feeding all snapshots in an epoch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f3ac4abd66cf680"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "Timestamp: 2023-12-28\n",
      "Pos score: tensor([11.8570,  9.9837, 10.7632], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([10.7834,  6.2852,  7.7267], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Loss: 4.1329498291015625\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2023-12-29\n",
      "Pos score: tensor([11.9501, 11.4129,  3.9887, 11.8570, 10.0561,  9.9837, 11.6577],\n",
      "       dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([5.1827, 8.8211, 1.8530, 7.1052, 6.8421, 7.4928, 5.0643],\n",
      "       dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.0385549068450928\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 0.9818, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 0.9818, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2023-12-30\n",
      "Pos score: tensor([ 9.0527, 10.6104,  7.0646], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([3.2599, 5.4730, 6.4996], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 2.546140432357788\n",
      "Pos probabilities: tensor([0.9999, 1.0000, 0.9991], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9999, 1.0000, 0.9991], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2023-12-31\n",
      "Pos score: tensor([8.3971, 8.3086, 9.9837], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([6.5283, 8.4526, 8.5175], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.916801691055298\n",
      "Pos probabilities: tensor([0.9998, 0.9998, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9998, 0.9998, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-01\n",
      "Pos score: tensor([10.6728,  4.8066, 10.3688, 10.4383], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([6.5351, 8.3147, 5.8882, 6.2001], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Loss: 3.3691024780273438\n",
      "Pos probabilities: tensor([1.0000, 0.9919, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 0.9919, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-02\n",
      "Pos score: tensor([10.5613,  9.9837], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([6.0466, 7.0421], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.2730002403259277\n",
      "Pos probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-03\n",
      "Pos score: tensor([ 9.9837,  3.1487, 10.0749], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([9.3625, 5.9060, 1.7746], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 2.8741061687469482\n",
      "Pos probabilities: tensor([1.0000, 0.9589, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 0.9589, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-04\n",
      "Pos score: tensor([11.9917, 11.8656,  9.9837, 10.0749,  2.8517, 10.4111],\n",
      "       dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([10.0216,  4.8767,  7.9041,  8.2703,  5.8825,  6.7735],\n",
      "       dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.649764060974121\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9454, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9454, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-05\n",
      "Pos score: tensor([10.0749], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([10.6654], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 5.3327155113220215\n",
      "Pos probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-07\n",
      "Pos score: tensor([10.8853], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([0.8262], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 0.5946449041366577\n",
      "Pos probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-08\n",
      "Pos score: tensor([11.7422, 11.8534, 11.1804], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([6.7581, 7.7232, 3.8396], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.0572919845581055\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-09\n",
      "Pos score: tensor([11.8055, 11.8914], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([4.1465, 4.0838], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 2.0656704902648926\n",
      "Pos probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-10\n",
      "Pos score: tensor([9.1013], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([7.2877], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.644268751144409\n",
      "Pos probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-11\n",
      "Pos score: tensor([11.5816,  9.1013], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([11.2024,  8.6368], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 4.959888935089111\n",
      "Pos probabilities: tensor([1.0000, 0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-12\n",
      "Pos score: tensor([11.9005, 11.7474,  9.1013], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([7.9333, 8.6270, 9.0130], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 4.262345790863037\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 0.9999], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 0.9999], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-13\n",
      "Pos score: tensor([8.7394, 9.1013], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([7.8066, 8.6988], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 4.126556873321533\n",
      "Pos probabilities: tensor([0.9998, 0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9998, 0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-14\n",
      "Pos score: tensor([11.1438, 10.8998], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([5.0965, 9.8123], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 3.7287509441375732\n",
      "Pos probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-15\n",
      "Pos score: tensor([9.7030], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([11.7127], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 5.856405258178711\n",
      "Pos probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-16\n",
      "Pos score: tensor([9.1613], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([2.7763], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 1.418387532234192\n",
      "Pos probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9999], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-17\n",
      "Pos score: tensor([10.9060, 11.2246, 11.2619], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([ 4.2318, 11.2944,  9.1355], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Loss: 4.112729072570801\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-18\n",
      "Pos score: tensor([11.8387], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([-0.9609], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 0.16197307407855988\n",
      "Pos probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-19\n",
      "Pos score: tensor([ 8.7858, 11.9948, 11.9062], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([5.9987, 9.3712, 9.8937], dtype=torch.float64, grad_fn=<SumBackward1>)\n",
      "Loss: 4.211080074310303\n",
      "Pos probabilities: tensor([0.9998, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([0.9998, 1.0000, 1.0000], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "####################################################################################################\n",
      "Timestamp: 2024-01-20\n",
      "Pos score: tensor([10.1839, 10.6480,  9.1589], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Neg score: tensor([ 5.6146,  9.0738, 11.0185], dtype=torch.float64,\n",
      "       grad_fn=<SumBackward1>)\n",
      "Loss: 4.285129547119141\n",
      "Pos probabilities: tensor([1.0000, 1.0000, 0.9999], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Neg probabilities: tensor([1.0000, 1.0000, 0.9999], dtype=torch.float64,\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_timestamps = len(train_timestamps) # ((num_timestamps-1)/2)+1 = 1 feature matrix for one timestamp\n",
    "tmp_model = STConv(None, num_nodes, nodes_df.shape[1]-1, 16, 12, int(((num_timestamps-1)/2)+1), 3).double()\n",
    "tmp_cls = Classifier()\n",
    "torch.no_grad()\n",
    "\n",
    "tmp_data = {'x':torch.stack([train_data[i].x for i in range(num_timestamps)], dim=0).unsqueeze(0),\n",
    "            'edge_index':[train_data[i].edge_index for i in range(num_timestamps)],\n",
    "            'edge_attr':[train_data[i].edge_attr for i in range(num_timestamps)]}\n",
    "tmp_h = tmp_model(tmp_data['x'], tmp_data['edge_index'], tmp_data['edge_attr']).squeeze()\n",
    "\n",
    "for t in range(num_timestamps):\n",
    "    pos_score = tmp_cls(tmp_h, train_pos_edges_data[t].edge_index)\n",
    "    neg_score = tmp_cls(tmp_h, train_neg_edges_data[t].edge_index)\n",
    "    print('#'*100)\n",
    "    print(f'Timestamp: {train_timestamps[t]}')\n",
    "    print(f'Pos score: {pos_score}')\n",
    "    print(f'Neg score: {neg_score}')\n",
    "    print(f'Loss: {compute_loss(pos_score, neg_score)}')\n",
    "    print(f'Pos probabilities: {torch.sigmoid(pos_score)}')\n",
    "    print(f'Neg probabilities: {torch.sigmoid(pos_score)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-22T19:05:19.614573400Z",
     "start_time": "2024-03-22T19:05:19.433063900Z"
    }
   },
   "id": "11d2f2092d0f14b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = None\n",
    "cls = None\n",
    "model_name = '' # example:stgnn-cnn-gnn\n",
    "\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), cls.parameters()), lr=lr)\n",
    "\n",
    "print(model)\n",
    "print(cls)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2bbe926e69bdff7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 777"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bebbc7040ec2198c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8381754ab3dff1f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_per_epoch = []\n",
    "acc_per_epoch = []\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    # forward\n",
    "    h = model()\n",
    "    pos_score = cls()\n",
    "    neg_score = cls()\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    acc = (pos_score > 0.5).mean\n",
    "    \n",
    "    loss_per_epoch.append()\n",
    "    acc_per_epoch.append()#(pos_score > 0.5).mean\n",
    "    \n",
    "    # backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print(\"In epoch {}, loss: {}\".format(e, loss))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29851b10ec4b5ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9982447f57fe07b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_train_metric(values_per_epoch, name):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(values_per_epoch, label='Train ' + name)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    plt.title('Training ' + name)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_train_metric(loss_per_epoch, 'Loss')\n",
    "plot_train_metric(loss_per_epoch, 'Accuracy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "205d78c6058a8361"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss_per_epoch, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(acc_per_epoch, label='Accuracy', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75915e19b4d35269"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the STGNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ec98c44d50a73ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "842308641667b37d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_size = test_timestamps.shape[0]\n",
    "loss = 0\n",
    "acc = 0\n",
    "auc = 0\n",
    "for pos_snapshot, neg_snapshot in zip(test_pos_dataset, test_neg_dataset):\n",
    "    # forward\n",
    "    h = model()\n",
    "    pos_score = cls()\n",
    "    neg_score = cls()\n",
    "    loss += compute_loss(pos_score, neg_score)\n",
    "    acc += (pos_score > 0.5).mean\n",
    "    auc += compute_auc(pos_score, neg_score)\n",
    "\n",
    "print(f'Loss:{loss/test_size}\\nAccuracy:{acc/test_size}\\nAuc:{auc/test_size}\\n')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f96de48cba30cbd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save learned parameters of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adeb28f0fd4aabdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if reduced:\n",
    "    model_savepath = f\"../models/{model_name}-reduced-{int(frac1 * 100)}.pth\"\n",
    "elif reduced_sample_alt_e:\n",
    "    if sampled1:\n",
    "        model_savepath = f\"../models/{model_name}-reduced-{int(frac2 * 100)}-h-{min_alt}-{max_alt}-e-{int(e_thres * 100)}.pth\"\n",
    "    else:\n",
    "        model_savepath = f\"../models/{model_name}-reduced-h-{min_alt}-{max_alt}-e-{int(e_thres * 100)}.pth\"\n",
    "elif reduced_sample_leos:\n",
    "    if sampled2:\n",
    "        model_savepath = f\"../models/{model_name}-{leo}-reduced-{int(frac3 * 100)}.pth\"\n",
    "    else:\n",
    "        model_savepath = f\"../models/{model_name}-{leo}.pth\"\n",
    "else:\n",
    "    model_savepath = '../models/{model_name}.pth'\n",
    "\n",
    "torch.save(model.state_dict(), model_savepath)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7fccd021fcbcc35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
